{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data=load_iris()\n",
    "X=data.data # the features\n",
    "y=data.target # the labels\n",
    "\n",
    "# split data into training and testing\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "# create and train the model\n",
    "model=LogisticRegression(max_iter=200)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "# make predictions\n",
    "y_pred=model.predict(X_test)\n",
    "\n",
    "# check how accurate the model is \n",
    "accuracy=accuracy_score(y_test,y_pred)\n",
    "print('accuracy:',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# calculate recall and F1-score\n",
    "# recall=recall_score(y_test,y_pred)\n",
    "f1=f1_score(y_test,y_pred)\n",
    "\n",
    "# print(f'recall:{recall:.2f}')\n",
    "print(f'F1 score:{f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean squared error: 0.555891598695242\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "data=fetch_california_housing()\n",
    "X=data.data\n",
    "y=data.target\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "model=LinearRegression()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "y_pred=model.predict(X_test)\n",
    "\n",
    "\n",
    "# mean squared error\n",
    "mse=mean_squared_error(y_test,y_pred)\n",
    "print('mean squared error:',mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data point 1: Cluster 0\n",
      "Data point 2: Cluster 0\n",
      "Data point 3: Cluster 2\n",
      "Data point 4: Cluster 0\n",
      "Data point 5: Cluster 1\n",
      "Data point 6: Cluster 1\n",
      "Data point 7: Cluster 1\n",
      "Data point 8: Cluster 2\n",
      "Data point 9: Cluster 2\n",
      "Data point 10: Cluster 1\n",
      "\n",
      "--- Clustering Metrics ---\n",
      "Silhouette Score: 0.82\n",
      "Davies-Bouldin Index: 0.19\n",
      "Calinski-Harabasz Index: 166.25\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "\n",
    "# Generate synthetic data\n",
    "X, y = make_blobs(n_samples=10, centers=3, random_state=42)\n",
    "\n",
    "# Create and fit the KMeans model\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Get the cluster labels\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Display the cluster assignments\n",
    "for i, label in enumerate(labels):\n",
    "    print(f'Data point {i+1}: Cluster {label}')\n",
    "\n",
    "print(\"\\n--- Clustering Metrics ---\")\n",
    "\n",
    "# 1. Silhouette Score (higher is better, range: [-1, 1])\n",
    "silhouette_avg = silhouette_score(X, labels)\n",
    "print(f'Silhouette Score: {silhouette_avg:.2f}')\n",
    "\n",
    "# 2. Davies-Bouldin Index (lower is better)\n",
    "davies_bouldin = davies_bouldin_score(X, labels)\n",
    "print(f'Davies-Bouldin Index: {davies_bouldin:.2f}')\n",
    "\n",
    "# 3. Calinski-Harabasz Index (higher is better)\n",
    "calinski_harabasz = calinski_harabasz_score(X, labels)\n",
    "print(f'Calinski-Harabasz Index: {calinski_harabasz:.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
