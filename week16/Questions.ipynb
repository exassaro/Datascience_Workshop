{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a1f355a",
   "metadata": {},
   "source": [
    "1. Load Data (sns.load_dataset(\"titanic\"))\n",
    "2. Impute Missing Values:\n",
    "\n",
    "    Fill age with median.\n",
    "    Fill embarked with mode.\n",
    "3. Categorical Encoding:\n",
    "\n",
    "    One-hot encode sex, embarked.\n",
    "4. Feature Splitting:\n",
    "\n",
    "    Split name into first_name and title using string operations.\n",
    "5. Discretization:\n",
    "\n",
    "    Bin age into categories (e.g., child, adult, senior).\n",
    "6. Scaling:\n",
    "\n",
    "    Use MinMaxScaler on fare.\n",
    "7. Handling Outliers:\n",
    "\n",
    "    Clip extreme fare values above the 95th percentile.\n",
    "8. Variable Transformation:\n",
    "\n",
    "    Apply log transformation to fare for skewnessÂ reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2229d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df=sns.load_dataset('titanic')\n",
    "\n",
    "df['age'].fillna(df['age'].median(),inplace=True)\n",
    "df['embarked'].fillna(df['embarked'].mode()[0],inplace=True)\n",
    "\n",
    "df=pd.get_dummies(df,columns=['sex','embarked'],drop_first=True)\n",
    "\n",
    "\n",
    "\n",
    "# def extract_name_title(name):\n",
    "#     if pd.isnull(name):\n",
    "#         return pd.Series(['Unknown', 'Unknown'])\n",
    "#     parts = name.split(',')\n",
    "#     first_name = parts[1].split()[1] if len(parts) > 1 else 'Unknown'\n",
    "#     title = parts[1].split('.')[0].strip() if '.' in parts[1] else 'Unknown'\n",
    "#     return pd.Series([first_name, title])\n",
    "\n",
    "# df[['first_name', 'title']] = df['name'].apply(extract_name_title)\n",
    "\n",
    "\n",
    "\n",
    "# def age_bin(age):\n",
    "#     if age < 18:\n",
    "#         return 'child'\n",
    "#     elif age < 60:\n",
    "#         return 'adult'\n",
    "#     else:\n",
    "#         return 'senior'\n",
    "\n",
    "# df['age_category'] = df['age'].apply(age_bin)\n",
    "\n",
    "labels=['child','adult','senior']\n",
    "bins=[18,40,60,np.inf]\n",
    "df['age_category']=pd.cut(df['age'],bins=bins,labels=labels,right=False)\n",
    "\n",
    "\n",
    "\n",
    "scaler=MinMaxScaler()\n",
    "df['fare_scaled']=scaler.fit_transform(df[['fare']])\n",
    "\n",
    "fare_95 = df['fare'].quantile(0.95)\n",
    "df['fare_clipped'] = np.clip(df['fare'], a_min=None, a_max=fare_95)\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666caef3",
   "metadata": {},
   "source": [
    "Part 1: Feature Engineering Task \n",
    "\n",
    "Dataset: Use Titanic or any dataset with mixed types.\n",
    "\n",
    "Tasks:\n",
    "\t1.\tImpute missing values (numeric and categorical separately).\n",
    "\n",
    "\t2.\tApply one categorical encoding technique.\n",
    "\n",
    "\t3.\tDiscretize a numeric column into bins.\n",
    "\t\n",
    "\t4.\tSplit a datetime feature into day/month/year.\n",
    "\n",
    "Part 2: Feature Selection Task \n",
    "\n",
    "Dataset: Use the output from Part 1.\n",
    "\n",
    "Tasks:\n",
    "\t\n",
    "\t1.\tApply a Filter method (e.g., SelectKBest).\n",
    "\t\n",
    "\t2.\tApply a Wrapper method (e.g., RFE with Logistic Regression).\n",
    "\t\n",
    "\t3.\tApply an Embedded method (e.g., feature importance using RandomForest).\n",
    "\t\n",
    "\t4.\tBriefly compare the selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eefa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "\n",
    "df=sns.load_dataset('titanic')\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "\n",
    "\n",
    "# View initial info\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252f195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Numeric imputation (e.g., Age)\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "df['Age'] = num_imputer.fit_transform(df[['Age']])\n",
    "\n",
    "# Categorical imputation (e.g., Embarked)\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "df['Embarked'] = cat_imputer.fit_transform(df[['Embarked']]).ravel()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa581943",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2200c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Fare_bin'] = pd.qcut(df['Fare'], q=4, labels=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbc2df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a fake datetime feature (random boarding dates)\n",
    "df['Boarded_date'] = pd.to_datetime('1912-04-01') + pd.to_timedelta(np.random.randint(0, 30, df.shape[0]), unit='D')\n",
    "\n",
    "# Extract day/month/year\n",
    "df['Boarded_day'] = df['Boarded_date'].dt.day\n",
    "df['Boarded_month'] = df['Boarded_date'].dt.month\n",
    "df['Boarded_year'] = df['Boarded_date'].dt.year\n",
    "\n",
    "# Drop the fake datetime\n",
    "df = df.drop(columns='Boarded_date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b0b5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183c3137",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Select top 5 features\n",
    "selector = SelectKBest(score_func=chi2, k=5)\n",
    "X_new_filter = selector.fit_transform(X, y)\n",
    "\n",
    "# Selected feature names\n",
    "selected_filter_features = X.columns[selector.get_support()]\n",
    "print(\"Filter method selected:\", list(selected_filter_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b584a118",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "rfe = RFE(estimator=model, n_features_to_select=5)\n",
    "rfe.fit(X, y)\n",
    "\n",
    "selected_wrapper_features = X.columns[rfe.support_]\n",
    "print(\"Wrapper method selected:\", list(selected_wrapper_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7e6bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X, y)\n",
    "\n",
    "# Feature importance ranking\n",
    "importances = rf.feature_importances_\n",
    "feat_imp = pd.Series(importances, index=X.columns).sort_values(ascending=False)\n",
    "selected_embedded_features = feat_imp.head(5).index.tolist()\n",
    "print(\"Embedded method selected:\", selected_embedded_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ac21a1",
   "metadata": {},
   "source": [
    "ðŸ“˜ Part 1: Data Preprocessing and Feature Engineering\n",
    "\n",
    "Dataset: Use any dataset with mixed data types (e.g., Titanic, House Prices, etc.)\n",
    "\n",
    "Tasks:\n",
    "\n",
    "Identify and handle missing values separately for numerical and categorical features.\n",
    "\n",
    "Apply an appropriate encoding strategy to convert categorical variables to numerical ones.\n",
    "\n",
    "Normalize or standardize at least one numerical feature.\n",
    "\n",
    "Create new date-based features (like weekday, quarter, etc.) from an existing datetime column.\n",
    "\n",
    "ðŸ“˜ Part 2: Feature Selection Techniques\n",
    "\n",
    "Dataset: Use the preprocessed output from Part 1.\n",
    "\n",
    "Tasks:\n",
    "\n",
    "Apply a Filter-based feature selection method (e.g., f_classif or mutual_info_classif).\n",
    "\n",
    "Apply a Wrapper-based method using RFE with a Decision Tree classifier.\n",
    "\n",
    "Apply an Embedded method using Lasso or any regularization technique.\n",
    "\n",
    "Compare the selected features across the three methods and briefly discuss any differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd69a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "print(sns.get_dataset_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa73498",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=sns.load_dataset('penguins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f408b17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886ca416",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952bc4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['sex'],inplace=True)\n",
    "df=pd.get_dummies(df,columns=['sex'],drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b61969e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le=LabelEncoder()\n",
    "\n",
    "df['species_encoded']=le.fit_transform(df[['species']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabe9c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce469d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler=StandardScaler()\n",
    "\n",
    "df['scaled_body_mass']=scaler.fit_transform(df[['body_mass_g']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ea4f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['scaled_body_mass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c932ee1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b199b47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.select_dtypes(include='number')\n",
    "y=df['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8954de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "filter_selector=SelectKBest(score_func=f_classif,k=5)\n",
    "filter_selector.fit(X,y)\n",
    "\n",
    "filter_selected=X.columns[filter_selector.get_support()]\n",
    "\n",
    "print(\"ðŸ”¹ Filter-based selected features:\", list(filter_selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f48e329",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model=DecisionTreeClassifier()\n",
    "rfe=RFE(estimator=model,n_features_to_select=5)\n",
    "rfe.fit(X,y)\n",
    "\n",
    "wrapper_selected=X.columns[rfe.support_]\n",
    "\n",
    "print(list(wrapper_selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d541f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "lasso_cv = LassoCV(alphas=[0.01, 0.1, 1.0, 10.0], cv=5)\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best alpha:\", lasso_cv.alpha_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exassaro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
